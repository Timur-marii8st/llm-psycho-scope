{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b943fa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-22T06:17:16.215541Z",
     "iopub.status.busy": "2026-02-22T06:17:16.214977Z",
     "iopub.status.idle": "2026-02-22T07:03:41.365841Z",
     "shell.execute_reply": "2026-02-22T07:03:41.364521Z"
    },
    "papermill": {
     "duration": 2785.209925,
     "end_time": "2026-02-22T07:03:41.420057",
     "exception": false,
     "start_time": "2026-02-22T06:17:16.210132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  : google/gemini-3-flash-preview\n",
      "Traits : 6 — ['Neuroticism', 'Extraversion', 'Conscientiousness', 'Agreeableness', 'Openness', 'Narcissism']\n",
      "Topics : 20\n",
      "Reps   : 3 per combo\n",
      "Total  : 1080 rows (raw)\n",
      "\n",
      "Generating 1080 texts (6 traits × 20 topics × 3 reps × 3 types)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  18%|█▊        | 199/1080 [09:03<46:25,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Extraversion|dealing with a broken household appliance|rep0] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  76%|███████▌  | 820/1080 [36:32<09:28,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|discussing a recent project they completed|rep0] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  76%|███████▋  | 826/1080 [36:49<10:15,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|discussing a recent project they completed|rep2] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  76%|███████▋  | 826/1080 [36:51<10:15,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|discussing a recent project they completed|rep2] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  77%|███████▋  | 829/1080 [37:01<13:18,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|reviewing a film they just watched|rep0] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  77%|███████▋  | 829/1080 [37:03<13:18,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|reviewing a film they just watched|rep0] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  81%|████████  | 874/1080 [38:47<08:22,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↺ Retry B [Openness|deciding what to have for lunch|rep0] (banned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 1080/1080 [46:23<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Full dataset → psych_trait_dataset_v2.parquet  (1080 rows)\n",
      "✓ Clean dataset → psych_trait_dataset_v2_clean.csv  (1080 rows)\n",
      "\n",
      "── Validation summary ───────────────────────────────────────\n",
      "shape: (3, 6)\n",
      "┌────────────┬───────┬────────┬───────────┬──────────────┬─────────┐\n",
      "│ data_type  ┆ total ┆ passed ┆ avg_words ┆ banned_found ┆ english │\n",
      "│ ---        ┆ ---   ┆ ---    ┆ ---       ┆ ---          ┆ ---     │\n",
      "│ str        ┆ u32   ┆ u32    ┆ f64       ┆ u32          ┆ u32     │\n",
      "╞════════════╪═══════╪════════╪═══════════╪══════════════╪═════════╡\n",
      "│ A_explicit ┆ 360   ┆ 360    ┆ 49.7      ┆ 0            ┆ 360     │\n",
      "│ B_implicit ┆ 360   ┆ 360    ┆ 55.0      ┆ 0            ┆ 360     │\n",
      "│ C_baseline ┆ 360   ┆ 360    ┆ 55.2      ┆ 0            ┆ 360     │\n",
      "└────────────┴───────┴────────┴───────────┴──────────────┴─────────┘\n",
      "\n",
      "── Per-trait counts ─────────────────────────────────────────\n",
      "shape: (18, 3)\n",
      "┌───────────────────┬────────────┬─────┐\n",
      "│ trait             ┆ data_type  ┆ len │\n",
      "│ ---               ┆ ---        ┆ --- │\n",
      "│ str               ┆ str        ┆ u32 │\n",
      "╞═══════════════════╪════════════╪═════╡\n",
      "│ Agreeableness     ┆ A_explicit ┆ 60  │\n",
      "│ Agreeableness     ┆ B_implicit ┆ 60  │\n",
      "│ Agreeableness     ┆ C_baseline ┆ 60  │\n",
      "│ Conscientiousness ┆ A_explicit ┆ 60  │\n",
      "│ Conscientiousness ┆ B_implicit ┆ 60  │\n",
      "│ …                 ┆ …          ┆ …   │\n",
      "│ Neuroticism       ┆ B_implicit ┆ 60  │\n",
      "│ Neuroticism       ┆ C_baseline ┆ 60  │\n",
      "│ Openness          ┆ A_explicit ┆ 60  │\n",
      "│ Openness          ┆ B_implicit ┆ 60  │\n",
      "│ Openness          ┆ C_baseline ┆ 60  │\n",
      "└───────────────────┴────────────┴─────┘\n",
      "\n",
      "── Statistical Power Report ─────────────────────────────────\n",
      "  Agreeableness         n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "  Conscientiousness     n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "  Extraversion          n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "  Narcissism            n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "  Neuroticism           n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "  Openness              n_B= 60  n_C= 60  medium(d=0.5)✓  small(d=0.2)✗\n",
      "\n",
      "  Need n≥25 for medium effect, n≥155 for small effect\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Psychological Trait Dataset Generator v2\n",
    "==========================================\n",
    "English-only dataset for SAE/mechanistic interpretability research.\n",
    "\n",
    "Design:\n",
    "  - 6 traits (Big Five + Narcissism)\n",
    "  - 20 diverse topics\n",
    "  - 3 repetitions per trait × topic combination\n",
    "  - 3 data types: A_explicit, B_implicit, C_baseline\n",
    "  - Total: 6 × 20 × 3 × 3 = 1080 rows (~918 after validation)\n",
    "  - n=60 per group → sufficient for medium effect size (d=0.5, α=0.05, power=0.80)\n",
    "\n",
    "Statistical power:\n",
    "  - Medium effect (d=0.5): need n=25, have n=60 ✓\n",
    "  - Small effect  (d=0.2): need n=155, have n=60 (partial coverage)\n",
    "\n",
    "Cost estimate: ~$0.06, ~14 minutes on Gemini 3 Flash via OpenRouter.\n",
    "\n",
    "Dependencies:\n",
    "  pip install polars httpx python-dotenv tqdm scipy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import httpx\n",
    "import polars as pl\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "openrouter_key = user_secrets.get_secret(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# ── Config ────────────────────────────────────────────────────────────────────\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\", openrouter_key)\n",
    "MODEL              = \"google/gemini-3-flash-preview\"\n",
    "TARGET_WORDS       = \"45-60 words\"    # controls token length consistency\n",
    "REPS_PER_COMBO     = 3                # different texts per (trait, topic) pair\n",
    "SLEEP_BETWEEN      = 0.6              # seconds between API calls\n",
    "MAX_RETRIES        = 3                # retries on validation failure\n",
    "\n",
    "# ── Traits ────────────────────────────────────────────────────────────────────\n",
    "# (trait_name, high_label, low_label, banned_keywords)\n",
    "# Banned keywords: must NOT appear in B_implicit / C_baseline texts.\n",
    "# Rule: if this word makes the label obvious, ban it.\n",
    "\n",
    "TRAITS = [\n",
    "    (\n",
    "        \"Neuroticism\",\n",
    "        \"Neurotic\",\n",
    "        \"Emotionally Stable\",\n",
    "        [\"neurotic\", \"neuroticism\", \"anxious\", \"anxiety\", \"worried\", \"worry\",\n",
    "         \"nervous\", \"panic\", \"stressed\", \"stress\", \"tense\", \"calm\", \"stable\",\n",
    "         \"relaxed\", \"composed\", \"serene\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Extraversion\",\n",
    "        \"Extravert\",\n",
    "        \"Introvert\",\n",
    "        [\"extravert\", \"extrovert\", \"introvert\", \"extroversion\", \"introversion\",\n",
    "         \"sociable\", \"outgoing\", \"shy\", \"reserved\", \"withdrawn\", \"social\",\n",
    "         \"loner\", \"people-person\", \"quiet\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Conscientiousness\",\n",
    "        \"Conscientious\",\n",
    "        \"Impulsive\",\n",
    "        [\"conscientious\", \"conscientiousness\", \"impulsive\", \"impulsivity\",\n",
    "         \"disciplined\", \"discipline\", \"organized\", \"disorganized\", \"careful\",\n",
    "         \"careless\", \"diligent\", \"lazy\", \"responsible\", \"irresponsible\",\n",
    "         \"systematic\", \"methodical\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Agreeableness\",\n",
    "        \"Agreeable\",\n",
    "        \"Antagonistic\",\n",
    "        [\"agreeable\", \"agreeableness\", \"antagonistic\", \"antagonism\",\n",
    "         \"cooperative\", \"uncooperative\", \"empathetic\", \"empathy\",\n",
    "         \"compassionate\", \"cold\", \"warm\", \"hostile\", \"kind\", \"unkind\",\n",
    "         \"trusting\", \"suspicious\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Openness\",\n",
    "        \"Open\",\n",
    "        \"Closed\",\n",
    "        [\"openness\", \"open-minded\", \"closed-minded\", \"creative\", \"uncreative\",\n",
    "         \"imaginative\", \"conventional\", \"curious\", \"incurious\", \"intellectual\",\n",
    "         \"narrow-minded\", \"artistic\", \"traditional\", \"innovative\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Narcissism\",\n",
    "        \"Narcissist\",\n",
    "        \"Humble\",\n",
    "        [\"narcissist\", \"narcissism\", \"narcissistic\", \"humble\", \"humility\",\n",
    "         \"arrogant\", \"arrogance\", \"egotistical\", \"ego\", \"self-centered\",\n",
    "         \"modest\", \"modesty\", \"conceited\", \"vain\", \"grandiose\"],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ── Topics ────────────────────────────────────────────────────────────────────\n",
    "# 20 diverse everyday situations — held constant across all traits.\n",
    "# Diversity across domains: domestic, social, work, emotional, planning.\n",
    "\n",
    "TOPICS = [\n",
    "    # Domestic\n",
    "    \"making a cup of tea or coffee\",\n",
    "    \"cooking dinner after a long day\",\n",
    "    \"dealing with a broken household appliance\",\n",
    "    \"describing their morning routine\",\n",
    "    # Social\n",
    "    \"meeting someone new at a party\",\n",
    "    \"giving directions to a stranger\",\n",
    "    \"talking about the weather with a neighbour\",\n",
    "    \"reacting to a friend cancelling plans last minute\",\n",
    "    # Work / productivity\n",
    "    \"being late to an important meeting\",\n",
    "    \"receiving critical feedback on their work\",\n",
    "    \"explaining how they organise their workspace\",\n",
    "    \"discussing a recent project they completed\",\n",
    "    # Emotional / evaluative\n",
    "    \"reviewing a film they just watched\",\n",
    "    \"reacting to unexpected good news\",\n",
    "    \"reacting to a minor personal failure\",\n",
    "    \"talking about a recent argument with someone\",\n",
    "    # Planning / future\n",
    "    \"planning a weekend trip\",\n",
    "    \"deciding what to have for lunch\",\n",
    "    \"choosing a new book or TV show to start\",\n",
    "    \"reflecting on a goal they have for next year\",\n",
    "]\n",
    "\n",
    "# ── Prompt builders ───────────────────────────────────────────────────────────\n",
    "\n",
    "def prompt_A(trait: str, pole: str, keywords: list[str], topic: str, rep: int) -> str:\n",
    "    \"\"\"\n",
    "    Type A — Explicit: third-person description containing trait keywords.\n",
    "    Used to discover SAE latents. Must include at least one banned keyword.\n",
    "    \"\"\"\n",
    "    kw_sample = \", \".join(f'\"{k}\"' for k in keywords[:5])\n",
    "    variety_hint = (\n",
    "        \"\" if rep == 0 else\n",
    "        \" Use a different sentence structure and framing than a typical description.\"\n",
    "        if rep == 1 else\n",
    "        \" Make this feel like a clinical psychological observation.\"\n",
    "    )\n",
    "    return f\"\"\"You are generating data for a psycholinguistics research dataset.\n",
    "\n",
    "Task: Write 1-2 sentences in THIRD PERSON ({TARGET_WORDS}) describing a person with a \\\n",
    "strongly expressed trait of \"{pole}\" ({trait}), in the context of: \"{topic}\".\n",
    "\n",
    "Requirements:\n",
    "- MUST include at least one of these keywords: {kw_sample}\n",
    "- Write in English only\n",
    "- Output ONLY the text, no quotes, no explanations\n",
    "- Length: {TARGET_WORDS}{variety_hint}\n",
    "\n",
    "Example format (do not copy): She is a textbook neurotic — even a minor delay \\\n",
    "sends her into a spiral of catastrophic thinking and physical tension.\"\"\"\n",
    "\n",
    "\n",
    "def prompt_B(trait: str, pole: str, keywords: list[str], topic: str, rep: int) -> str:\n",
    "    \"\"\"\n",
    "    Type B — Implicit: first-person speech expressing the trait through style only.\n",
    "    No trait keywords allowed. Core test of the hypothesis.\n",
    "    \"\"\"\n",
    "    forbidden = \", \".join(f'\"{k}\"' for k in keywords)\n",
    "    variety_hint = (\n",
    "        \"\" if rep == 0 else\n",
    "        \" The speaker is in a slightly different mood than usual.\"\n",
    "        if rep == 1 else\n",
    "        \" Focus on the speaker's choice of words and sentence rhythm, not just content.\"\n",
    "    )\n",
    "    return f\"\"\"You are generating data for a psycholinguistics research dataset.\n",
    "\n",
    "Task: Write FIRST-PERSON speech ({TARGET_WORDS}) of a person talking about: \"{topic}\".\n",
    "The speaker has a strongly expressed character trait: \"{pole}\" ({trait}).\n",
    "\n",
    "STRICT CONSTRAINTS:\n",
    "- ABSOLUTELY DO NOT use any of these words or their derivatives: {forbidden}\n",
    "- Do NOT name the trait explicitly in any form\n",
    "- Convey the personality ONLY through: word choice, syntax, emotional tone, \\\n",
    "level of detail, sentence structure\n",
    "- English only\n",
    "- Output ONLY the speech text, no labels, no explanations\n",
    "- Length: {TARGET_WORDS}{variety_hint}\"\"\"\n",
    "\n",
    "\n",
    "def prompt_C(trait: str, pole: str, keywords: list[str], topic: str, rep: int) -> str:\n",
    "    \"\"\"\n",
    "    Type C — Baseline/Control: opposite pole, same topic, no keywords.\n",
    "    Activation of the B-latent should be near zero here.\n",
    "    \"\"\"\n",
    "    forbidden = \", \".join(f'\"{k}\"' for k in keywords)\n",
    "    variety_hint = (\n",
    "        \"\" if rep == 0 else\n",
    "        \" The speaker is slightly more talkative than usual.\"\n",
    "        if rep == 1 else\n",
    "        \" Make the contrast with the high-pole version as stark as possible.\"\n",
    "    )\n",
    "    return f\"\"\"You are generating data for a psycholinguistics research dataset.\n",
    "\n",
    "Task: Write FIRST-PERSON speech ({TARGET_WORDS}) of a person talking about: \"{topic}\".\n",
    "The speaker represents the OPPOSITE extreme of \"{pole}\" ({trait}) — \\\n",
    "meaning they are at the low pole of this personality dimension.\n",
    "\n",
    "STRICT CONSTRAINTS:\n",
    "- ABSOLUTELY DO NOT use any of these words or their derivatives: {forbidden}\n",
    "- Do NOT name any personality trait explicitly\n",
    "- Convey the personality ONLY through: word choice, syntax, emotional tone, \\\n",
    "level of detail, sentence structure\n",
    "- English only\n",
    "- Output ONLY the speech text, no labels, no explanations\n",
    "- Length: {TARGET_WORDS}{variety_hint}\"\"\"\n",
    "\n",
    "\n",
    "# ── API call ──────────────────────────────────────────────────────────────────\n",
    "\n",
    "def call_llm(prompt: str, temperature: float = 0.9) -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": \"https://psych-trait-research.local\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 200,\n",
    "    }\n",
    "    for attempt in range(1, 4):\n",
    "        try:\n",
    "            with httpx.Client(timeout=60) as client:\n",
    "                resp = client.post(\n",
    "                    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers=headers, json=payload,\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "                return resp.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        except Exception as e:\n",
    "            if attempt == 3:\n",
    "                return \"\"\n",
    "            time.sleep(2 ** attempt)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ── Validation ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def contains_banned(text: str, keywords: list[str]) -> bool:\n",
    "    t = text.lower()\n",
    "    return any(kw.lower() in t for kw in keywords)\n",
    "\n",
    "\n",
    "def is_english(text: str, threshold: float = 0.7) -> bool:\n",
    "    \"\"\"Rough check: most alphabetic chars should be ASCII.\"\"\"\n",
    "    alpha = [c for c in text if c.isalpha()]\n",
    "    if not alpha:\n",
    "        return False\n",
    "    ascii_alpha = sum(1 for c in alpha if ord(c) < 128)\n",
    "    return ascii_alpha / len(alpha) >= threshold\n",
    "\n",
    "\n",
    "def word_count(text: str) -> int:\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "# ── Generation loop ───────────────────────────────────────────────────────────\n",
    "\n",
    "def generate_dataset() -> pl.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    combos = [\n",
    "        (trait_tuple, topic, rep)\n",
    "        for trait_tuple, topic, rep\n",
    "        in product(TRAITS, TOPICS, range(REPS_PER_COMBO))\n",
    "    ]\n",
    "    total_calls = len(combos) * 3   # A + B + C per combo\n",
    "\n",
    "    print(f\"Generating {total_calls} texts \"\n",
    "          f\"({len(TRAITS)} traits × {len(TOPICS)} topics × \"\n",
    "          f\"{REPS_PER_COMBO} reps × 3 types)\")\n",
    "\n",
    "    with tqdm(total=total_calls, desc=\"Generating\") as pbar:\n",
    "        for (trait_name, high_label, low_label, ban_words), topic, rep in combos:\n",
    "\n",
    "            # Slight temperature variation across reps for lexical diversity\n",
    "            temp = 0.85 + rep * 0.05   # 0.85 / 0.90 / 0.95\n",
    "\n",
    "            # ── Type A ──────────────────────────────────────────────────────\n",
    "            for attempt in range(MAX_RETRIES + 1):\n",
    "                text_a = call_llm(prompt_A(trait_name, high_label, ban_words, topic, rep), temp)\n",
    "                time.sleep(SLEEP_BETWEEN)\n",
    "                if text_a and is_english(text_a):\n",
    "                    break\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    tqdm.write(f\"  ↺ Retry A [{trait_name}|{topic}|rep{rep}]\")\n",
    "\n",
    "            rows.append({\n",
    "                \"id\": f\"A_{trait_name}_{high_label}_{rep}_{topic[:25]}\",\n",
    "                \"data_type\": \"A_explicit\",\n",
    "                \"trait\": trait_name,\n",
    "                \"pole\": high_label,\n",
    "                \"topic\": topic,\n",
    "                \"rep\": rep,\n",
    "                \"text\": text_a,\n",
    "                \"word_count\": word_count(text_a),\n",
    "                \"is_english\": is_english(text_a),\n",
    "                \"contains_banned\": None,   # A should contain keywords\n",
    "                \"validation_passed\": bool(text_a) and is_english(text_a),\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "            # ── Type B ──────────────────────────────────────────────────────\n",
    "            text_b, banned_b = \"\", True\n",
    "            for attempt in range(MAX_RETRIES + 1):\n",
    "                text_b = call_llm(prompt_B(trait_name, high_label, ban_words, topic, rep), temp)\n",
    "                time.sleep(SLEEP_BETWEEN)\n",
    "                banned_b = contains_banned(text_b, ban_words) if text_b else True\n",
    "                not_en   = not is_english(text_b) if text_b else True\n",
    "                if text_b and not banned_b and not not_en:\n",
    "                    break\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    reason = \"banned\" if banned_b else (\"not-EN\" if not_en else \"empty\")\n",
    "                    tqdm.write(f\"  ↺ Retry B [{trait_name}|{topic}|rep{rep}] ({reason})\")\n",
    "\n",
    "            rows.append({\n",
    "                \"id\": f\"B_{trait_name}_{high_label}_{rep}_{topic[:25]}\",\n",
    "                \"data_type\": \"B_implicit\",\n",
    "                \"trait\": trait_name,\n",
    "                \"pole\": high_label,\n",
    "                \"topic\": topic,\n",
    "                \"rep\": rep,\n",
    "                \"text\": text_b,\n",
    "                \"word_count\": word_count(text_b),\n",
    "                \"is_english\": is_english(text_b) if text_b else False,\n",
    "                \"contains_banned\": banned_b,\n",
    "                \"validation_passed\": bool(text_b) and not banned_b and is_english(text_b),\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "            # ── Type C ──────────────────────────────────────────────────────\n",
    "            text_c, banned_c = \"\", True\n",
    "            for attempt in range(MAX_RETRIES + 1):\n",
    "                text_c = call_llm(prompt_C(trait_name, high_label, ban_words, topic, rep), temp)\n",
    "                time.sleep(SLEEP_BETWEEN)\n",
    "                banned_c = contains_banned(text_c, ban_words) if text_c else True\n",
    "                not_en   = not is_english(text_c) if text_c else True\n",
    "                if text_c and not banned_c and not not_en:\n",
    "                    break\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    reason = \"banned\" if banned_c else (\"not-EN\" if not_en else \"empty\")\n",
    "                    tqdm.write(f\"  ↺ Retry C [{trait_name}|{topic}|rep{rep}] ({reason})\")\n",
    "\n",
    "            rows.append({\n",
    "                \"id\": f\"C_{trait_name}_{low_label}_{rep}_{topic[:25]}\",\n",
    "                \"data_type\": \"C_baseline\",\n",
    "                \"trait\": trait_name,\n",
    "                \"pole\": low_label,\n",
    "                \"topic\": topic,\n",
    "                \"rep\": rep,\n",
    "                \"text\": text_c,\n",
    "                \"word_count\": word_count(text_c),\n",
    "                \"is_english\": is_english(text_c) if text_c else False,\n",
    "                \"contains_banned\": banned_c,\n",
    "                \"validation_passed\": bool(text_c) and not banned_c and is_english(text_c),\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "    return pl.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ── Statistical power report ──────────────────────────────────────────────────\n",
    "\n",
    "def power_report(df: pl.DataFrame) -> None:\n",
    "    print(\"\\n── Statistical Power Report ─────────────────────────────────\")\n",
    "\n",
    "    def n_needed(d: float, alpha: float = 0.05, power: float = 0.80) -> int:\n",
    "        z_a, z_b = 1.645, 0.842\n",
    "        return math.ceil(((z_a + z_b) / d) ** 2)\n",
    "\n",
    "    for trait in sorted(df[\"trait\"].unique().to_list()):\n",
    "        n_b = len(df.filter(\n",
    "            (pl.col(\"trait\") == trait) &\n",
    "            (pl.col(\"data_type\") == \"B_implicit\") &\n",
    "            (pl.col(\"validation_passed\") == True)\n",
    "        ))\n",
    "        n_c = len(df.filter(\n",
    "            (pl.col(\"trait\") == trait) &\n",
    "            (pl.col(\"data_type\") == \"C_baseline\") &\n",
    "            (pl.col(\"validation_passed\") == True)\n",
    "        ))\n",
    "        n_min = min(n_b, n_c)\n",
    "        covers_medium = \"✓\" if n_min >= n_needed(0.5) else \"✗\"\n",
    "        covers_small  = \"✓\" if n_min >= n_needed(0.2) else \"✗\"\n",
    "        print(f\"  {trait:20s}  n_B={n_b:3d}  n_C={n_c:3d}  \"\n",
    "              f\"medium(d=0.5){covers_medium}  small(d=0.2){covers_small}\")\n",
    "\n",
    "    print(f\"\\n  Need n≥{n_needed(0.5)} for medium effect, n≥{n_needed(0.2)} for small effect\")\n",
    "\n",
    "\n",
    "# ── Main ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Model  : {MODEL}\")\n",
    "    print(f\"Traits : {len(TRAITS)} — {[t[0] for t in TRAITS]}\")\n",
    "    print(f\"Topics : {len(TOPICS)}\")\n",
    "    print(f\"Reps   : {REPS_PER_COMBO} per combo\")\n",
    "    print(f\"Total  : {len(TRAITS) * len(TOPICS) * REPS_PER_COMBO * 3} rows (raw)\\n\")\n",
    "\n",
    "    df = generate_dataset()\n",
    "\n",
    "    # Save full\n",
    "    df.write_parquet(\"data/psych_trait_dataset_v2.parquet\")\n",
    "    print(f\"\\n✓ Full dataset → data/psych_trait_dataset_v2.parquet  ({len(df)} rows)\")\n",
    "\n",
    "    # Save clean (validated only)\n",
    "    clean = df.filter(pl.col(\"validation_passed\") == True)\n",
    "    clean.write_csv(\"data/psych_trait_dataset_v2_clean.csv\")\n",
    "    clean.write_parquet(\"data/psych_trait_dataset_v2_clean.parquet\")\n",
    "    print(f\"✓ Clean dataset → data/psych_trait_dataset_v2_clean.csv  ({len(clean)} rows)\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n── Validation summary ───────────────────────────────────────\")\n",
    "    print(df.group_by([\"data_type\"]).agg([\n",
    "        pl.len().alias(\"total\"),\n",
    "        pl.col(\"validation_passed\").sum().alias(\"passed\"),\n",
    "        pl.col(\"word_count\").mean().round(1).alias(\"avg_words\"),\n",
    "        pl.col(\"contains_banned\").sum().alias(\"banned_found\"),\n",
    "        pl.col(\"is_english\").sum().alias(\"english\"),\n",
    "    ]).sort(\"data_type\"))\n",
    "\n",
    "    print(\"\\n── Per-trait counts ─────────────────────────────────────────\")\n",
    "    print(clean.group_by([\"trait\", \"data_type\"]).len().sort([\"trait\", \"data_type\"]))\n",
    "\n",
    "    power_report(clean)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2789.280217,
   "end_time": "2026-02-22T07:03:42.101629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-22T06:17:12.821412",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
